# Black-jack reinforcement-learning

The Black-Jack reinforcement learning project solves the game of black-jack training an epsilon greedy Q-learning agent to learn an optimal policy of the game. It proves that the Nash equilibrium of the game lies in the favor of the dealer and shows that a policy exist that gains a statistical advantage over the dealer if the ability of counting cards is introduced to the agent.

![rendered_network](/assets/q_surface.gif)

The animation above shows the resulting Q-surface post the training session for different deck-counts ranging from -20 to 20. Below is an animation showing the forming of the q-surface during the training of the Q-agent.

![rendered_network](/assets/q_surface_training.gif)


# Possible actions
- Hit
- Stay
- Double-down
- Split  

